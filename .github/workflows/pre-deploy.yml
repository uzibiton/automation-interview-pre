name: 'Main1: Pre-Deploy'

# Reusable workflow for pre-deployment checks (static analysis, tests)
# Can be triggered standalone or called by ALL workflow

on:
  # Standalone trigger - select branch to run checks on
  workflow_dispatch:
    inputs:
      skip_static_analysis:
        description: 'Skip static analysis'
        type: boolean
        default: false
      skip_unit_tests:
        description: 'Skip unit tests'
        type: boolean
        default: false
      skip_coverage:
        description: 'Skip coverage report'
        type: boolean
        default: false
      skip_prettier:
        description: 'Skip Prettier check'
        type: boolean
        default: false
      skip_eslint:
        description: 'Skip ESLint'
        type: boolean
        default: false
      skip_typecheck:
        description: 'Skip TypeScript check'
        type: boolean
        default: false
      skip_audit:
        description: 'Skip npm audit'
        type: boolean
        default: false
      skip_snyk:
        description: 'Skip Snyk scan'
        type: boolean
        default: false

  # Called by Main Flow
  workflow_call:
    inputs:
      skip_static_analysis:
        type: boolean
        default: false
      skip_unit_tests:
        type: boolean
        default: false
      skip_coverage:
        type: boolean
        default: false
      skip_prettier:
        type: boolean
        default: false
      skip_eslint:
        type: boolean
        default: false
      skip_typecheck:
        type: boolean
        default: false
      skip_audit:
        type: boolean
        default: false
      skip_snyk:
        type: boolean
        default: false
    secrets:
      SNYK_TOKEN:
        required: false
    outputs:
      timestamp:
        description: 'CI Run timestamp'
        value: ${{ jobs.generate-timestamp.outputs.timestamp }}
      all_passed:
        description: 'Whether all checks passed'
        value: ${{ jobs.static-analysis-gate.outputs.all_passed }}

jobs:
  # ============================================================================
  # Generate CI Run Timestamp (shared across all jobs)
  # ============================================================================

  generate-timestamp:
    name: Generate CI Run ID
    runs-on: ubuntu-latest
    outputs:
      timestamp: ${{ steps.timestamp.outputs.value }}
    steps:
      - name: Generate timestamp for this CI run
        id: timestamp
        run: echo "value=$(date -u +%Y-%m-%dT%H-%M-%S-%3NZ)" >> $GITHUB_OUTPUT

  # ============================================================================
  # STAGE 1: Static Analysis (parallel execution)
  # ============================================================================

  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    needs: [generate-timestamp]
    steps:
      - name: Start Code Quality Checks
        run: echo "Starting code quality checks"

  security-checks:
    name: Security Checks
    runs-on: ubuntu-latest
    needs: [generate-timestamp]
    steps:
      - name: Start Security Checks
        run: echo "Starting security checks"

  prettier:
    name: Code Formatting
    needs: [code-quality]
    runs-on: ubuntu-latest
    if: ${{ !inputs.skip_prettier }}
    continue-on-error: true

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm ci

      - name: Check formatting
        run: npm run format:check

  eslint:
    name: Linting
    needs: [code-quality]
    runs-on: ubuntu-latest
    if: ${{ !inputs.skip_eslint }}
    continue-on-error: true

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm ci

      - name: Run ESLint
        run: npm run lint

  typecheck:
    name: Type Check
    needs: [code-quality]
    runs-on: ubuntu-latest
    if: ${{ !inputs.skip_typecheck }}
    continue-on-error: true

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm ci

      - name: Type check
        run: npm run type-check

  npm-audit:
    name: Dependency Audit
    needs: [security-checks]
    runs-on: ubuntu-latest
    if: ${{ !inputs.skip_audit }}
    continue-on-error: true

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Run npm audit
        run: npm audit --audit-level=moderate

  snyk:
    name: Security Scan
    needs: [security-checks, generate-timestamp]
    runs-on: ubuntu-latest
    if: ${{ !inputs.skip_snyk }}
    permissions:
      contents: read
      security-events: write
      actions: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Run Snyk scan
        id: snyk
        continue-on-error: true
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high --all-projects --sarif-file-output=snyk.sarif

      - name: Organize security results
        if: always() && hashFiles('snyk.sarif') != ''
        run: |
          mkdir -p reports/${{ needs.generate-timestamp.outputs.timestamp }}/security-scan
          mv snyk.sarif reports/${{ needs.generate-timestamp.outputs.timestamp }}/security-scan/

      - name: Upload SARIF as artifact
        if: always() && steps.snyk.outcome != 'skipped'
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-${{ needs.generate-timestamp.outputs.timestamp }}
          path: reports/${{ needs.generate-timestamp.outputs.timestamp }}/security-scan/
          retention-days: 30

      - name: Upload results to GitHub Security
        if: always() && steps.snyk.outcome != 'skipped'
        continue-on-error: true
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: reports/${{ needs.generate-timestamp.outputs.timestamp }}/security-scan/snyk.sarif
          category: snyk-security-scan

      - name: Fail on vulnerabilities (non-blocking)
        if: steps.snyk.outcome == 'failure'
        run: |
          echo "ERROR: Snyk found high or critical vulnerabilities!"
          echo "Review the SARIF artifact or GitHub Security tab for details"
          exit 1

  # ============================================================================
  # STAGE 2: Unit Tests (runs in parallel with static analysis)
  # ============================================================================

  unit-tests:
    name: Unit Tests
    needs: [generate-timestamp]
    if: ${{ !inputs.skip_unit_tests }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install workspace dependencies
        run: npm ci

      - name: Cache node_modules
        id: cache-node-modules
        uses: actions/cache@v4
        with:
          path: tests/node_modules
          key: ${{ runner.os }}-test-modules-${{ hashFiles('tests/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-test-modules-

      - name: Install test dependencies
        if: steps.cache-node-modules.outputs.cache-hit != 'true'
        run: npm ci
        working-directory: tests

      - name: Run unit tests
        run: npm run test:unit -- --maxWorkers=2 --forceExit
        working-directory: tests
        timeout-minutes: 5

      - name: Organize test results
        if: always()
        run: |
          mkdir -p reports/${{ needs.generate-timestamp.outputs.timestamp }}/unit-tests
          if [ -d "reports" ]; then
            find reports -maxdepth 1 -type f -exec mv {} reports/${{ needs.generate-timestamp.outputs.timestamp }}/unit-tests/ \; 2>/dev/null || true
          fi
        working-directory: tests

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-tests-${{ needs.generate-timestamp.outputs.timestamp }}
          path: tests/reports/${{ needs.generate-timestamp.outputs.timestamp }}/unit-tests/

  # ============================================================================
  # STAGE 2.5: Code Coverage (runs after unit tests)
  # ============================================================================

  coverage:
    name: Code Coverage
    needs: [generate-timestamp, unit-tests]
    if: ${{ !inputs.skip_coverage && !inputs.skip_unit_tests }}
    runs-on: ubuntu-latest
    continue-on-error: true

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: tests/package-lock.json

      - name: Cache node_modules
        id: cache-node-modules
        uses: actions/cache@v4
        with:
          path: tests/node_modules
          key: ${{ runner.os }}-test-modules-${{ hashFiles('tests/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-test-modules-

      - name: Install test dependencies
        if: steps.cache-node-modules.outputs.cache-hit != 'true'
        run: npm ci
        working-directory: tests

      - name: Run tests with coverage
        run: npm run test:coverage -- --maxWorkers=2 --forceExit
        working-directory: tests
        timeout-minutes: 10

      - name: Organize coverage results
        if: always()
        run: |
          mkdir -p reports/${{ needs.generate-timestamp.outputs.timestamp }}/coverage
          if [ -d "coverage" ]; then
            mv coverage reports/${{ needs.generate-timestamp.outputs.timestamp }}/coverage/
          fi
        working-directory: tests

      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ needs.generate-timestamp.outputs.timestamp }}
          path: tests/reports/${{ needs.generate-timestamp.outputs.timestamp }}/coverage/

  # ============================================================================
  # Static Analysis Gate - Check if all static stages passed
  # ============================================================================
  static-analysis-gate:
    name: Static Analysis Gate
    needs: [prettier, eslint, typecheck, npm-audit, snyk, unit-tests, coverage]
    if: always()
    runs-on: ubuntu-latest
    outputs:
      all_passed: ${{ steps.check.outputs.all_passed }}

    steps:
      - name: Check static analysis results
        id: check
        run: |
          echo "Prettier: ${{ needs.prettier.result }}"
          echo "ESLint: ${{ needs.eslint.result }}"
          echo "TypeCheck: ${{ needs.typecheck.result }}"
          echo "npm audit: ${{ needs.npm-audit.result }}"
          echo "Snyk: ${{ needs.snyk.result }}"
          echo "Unit Tests: ${{ needs.unit-tests.result }}"
          echo "Coverage: ${{ needs.coverage.result }}"

          # Check for success or skipped (skipped is ok if intentionally skipped)
          PRETTIER="${{ needs.prettier.result }}"
          ESLINT="${{ needs.eslint.result }}"
          TYPECHECK="${{ needs.typecheck.result }}"
          AUDIT="${{ needs.npm-audit.result }}"
          SNYK="${{ needs.snyk.result }}"
          UNIT="${{ needs.unit-tests.result }}"
          COVERAGE="${{ needs.coverage.result }}"

          # All must be success or skipped
          if [[ "$PRETTIER" =~ ^(success|skipped)$ ]] && \
             [[ "$ESLINT" =~ ^(success|skipped)$ ]] && \
             [[ "$TYPECHECK" =~ ^(success|skipped)$ ]] && \
             [[ "$AUDIT" =~ ^(success|skipped)$ ]] && \
             [[ "$SNYK" =~ ^(success|skipped)$ ]] && \
             [[ "$UNIT" =~ ^(success|skipped)$ ]] && \
             [[ "$COVERAGE" =~ ^(success|skipped)$ ]]; then
            echo "All static analysis stages passed or skipped"
            echo "all_passed=true" >> $GITHUB_OUTPUT
          else
            echo "ERROR: Some static analysis stages failed."
            echo "all_passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
